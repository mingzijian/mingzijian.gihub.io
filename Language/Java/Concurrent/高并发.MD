高并发
---------
高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证系统能够同时并行处理很多请求。

### 高并发系统设计
#### 设计目标
##### 宏观目标
高性能/高可用/高可拓展

###### 高性能
性能体现了系统的并行处理能力。
从硬件投入来说，提升性能意味着节省成本。
从用户体验来说，提升性能意味着提升用户满意度。

###### 高可用
可用表示系统可以正常提供服务。
没人乐意访问一个经常宕机的网站。

###### 高可拓展
可拓展表示系统的拓展能力。
短时间内完成扩容，平稳应对高峰流量。
高峰退去时，安全缩容。

##### 微观指标
衡量宏观目标的具体指标
性能指标/可用性指标/可拓展性指标
###### 性能指标
- 响应时间(RT)
  
  响应时间低于200ms用户感觉不到延迟;1s响应时间是用户能感觉到但是可以接受的延迟.
  
  - 平均响应时间
	Avg = ( T1 + T2 + T3 + ... + Tn) / n
	缺点：对慢请求不敏感。（比如1W次请求，其中100次响应时间为100ms，其他9900次响应时间为1ms，不难算出平均响应时间为：1.99ms。虽然平均响应时间只多了0.99ms，但有1%的请求响应时间增加了100倍）
  - 百分位数响应时间
	百分位数：统计学术语，如果将一组数据从小到大排序，并计算相应的累计百分位，则某一百分位所对应数据的值就称为这一百分位的百分位数。可表示为：一组n个观测值按数值大小排列。如，处于p%位置的值称第p百分位数。(p值越大，对慢请求越敏感)
      - P50:
		即中位数值。100个请求按照响应时间从小到大排列，位置为50的值，即为P50值。如果响应时间的P50值为200ms，代表我们有半数的用户响应耗时在200ms之内，有半数的用户响应耗时大于200ms。
      - P99: 100个请求按照响应时间从小到大排列，假设P99=200ms，即只有1%的用户的响应耗时大于200ms。
      - P99.9: 许多大型的互联网公司会采用P99.9值，也就是99.9%用户耗时作为指标。至于P99.99，优化成本过高，而且服务响应由于网络波动、系统抖动等情况不能解决，因此大多数时候不考虑该指标。
    
	对于一个健康的高并发系统,P99建议控制在200ms内,P99.9建议控制在1s内.
	
- 并发数
	系统同时能处理的请求数量
- 吞吐量(Throughput) 
  - QPS（Queries Per Second）
  	意思是“每秒查询率”，是一台服务器每秒能够响应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。
	简单说，QPS = 请求数/秒。它代表的是服务器的机器的性能最大吞吐能力。
  - TPS （Transactions Per Second）
  	每秒处理的事务数。

###### 可用性指标
可用率 = 正常运行时间 / 总运行时间
类似金属纯度，一般用几个9来描述系统可用性。

| 可用性          | 年故障时长 | 日故障时长 |
| --------------- | ---------- | ---------- |
| 90% （1个9）    | 36.5天     | 2.4小时    |
| 99%（2个9）     | 3.65天     | 14.4分钟   |
| 99.9%（3个9）   | 8.76小时   | 1.44分钟   |
| 99.99%（4个9）  | 52.56分钟  | 8.64秒     |
| 99.999%（5个9） | 5.26分钟   | 0.86秒     |


###### 可拓展性指标
横向拓展/纵向拓展

### 知识点
#### CPU 缓存
cpu缓存是位于CPU与内存之间的**临时**存储器，它的容量比内存**小**的多，但是交换速度却比内存要**快**得多。
##### CPU缓存的意义
CPU往往需要重复处理相同的数据、重复执行相同的指令，如果这部分数据、指令CPU能在CPU缓存中找到，CPU就不需要从内存或硬盘中再读取数据、指令，从而缩短了整机的响应时间。
所以，缓存的意义满足以下两种局部性原理：
 - 时间局部性（Temporal Locality）：
	如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。
 - 空间局部性（Spatial Locality）：
	如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。

##### 多级缓存
随着多核CPU的发展，CPU缓存通常分成了三个级别：L1，L2，L3。
级别越小越接近CPU，所以速度也更快，同时也代表着容量越小。
##### 缓存一致性
CPU缓存一致性协议(MESI)
MESI（Modified Exclusive Shared Or Invalid）是一种广泛使用的支持写回策略的缓存一致性协议。
为了保证多个CPU缓存中共享数据的一致性，定义了缓存行(Cache Line)的四种状态，而CPU对缓存行的四种操作可能会产生不一致的状态，因此缓存控制器监听到本地操作和远程操作的时候，需要对地址一致的缓存行的状态进行一致性修改，从而保证数据在多个缓存之间保持一致性。

| 状态(2bit)               | 描述                                                         | 监听任务                                                     | 状态转换                                                     |
| ------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| M 修改 (Modified)        | 该Cache line有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。 | 缓存行必须时刻监听所有试图读该缓存行相对就主存的操作，这种操作必须在缓存将该缓存行写回主存并将状态变成S（共享）状态之前被延迟执行。 | 当被写回主存之后，该缓存行的状态会变成独享（exclusive)状态。 |
| E 独享 (Exclusive) | 该Cache line有效，数据和内存中的数据一致，数据只存在于本Cache中。 | 缓存行也必须监听其它缓存读主存中该缓存行的操作，一旦有这种操作，该缓存行需要变成S（共享）状态。 | 当CPU修改该缓存行中内容时，该状态可以变成Modified状态        |
| S 共享 (Shared)          | 该Cache line有效，数据和内存中的数据一致，数据存在于很多Cache中。 | 缓存行也必须监听其它缓存使该缓存行无效或者独享该缓存行的请求，并将该缓存行变成无效（Invalid）。 | 当有一个CPU修改该缓存行时，其它CPU中该缓存行可以被作废（变成无效状态 Invalid）。 |
| I 无效 (Invalid)         | 该Cache line无效。                                           | 无                                                           | 无                                                           |


##### 乱序执行优化
乱序执行（Out-Of-Order Execution）简称OOE。是指CPU采用了允许将多条指令不按程序规定的顺序分开发送给各相应电路单元处理的技术。
#### Java 内存模型
Java内存模型 (Java Memory Model) 简称JMM。JMM定义了程序中各个共享变量的访问规则,即在虚拟机中将变量存储到内存和从内存读取变量这样的底层细节。
##### 主内存,工作内存和线程三者的交互关系
JMM规定了共享变量都存储在主内存中。
每条线程有自己的工作内存, 线程的工作内存保存了主内存的副本拷贝,
对变量的操作在工作内存中进行, 不能直接操作主内存中的变量。
不同线程间无法直接访问对方的工作内存变量,需要通过主内存完成。

##### JMM 操作（原子操作）
- lock （锁定）
	作用于主内存的变量，把一个变量标识为线程独占状态
- unlock （解锁）
	作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定
- read （读取）
	作用于主内存变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用
- load （载入）
	作用于工作内存的变量，它把read操作从主存中变量放入工作内存中
- use （使用）
	作用于工作内存中的变量，它把工作内存中的变量传输给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时就会执行该操作
- assign （赋值）
	作用于工作内存中的变量，它把一个从执行引擎中接受到的值放入工作内存的变量副本中，每当虚拟机遇到一个给变量赋值的字节码指令时就会执行该操作
- store （存储）
	作用于主内存中的变量，它把一个从工作内存中一个变量的值传送到主内存中，以便后续的write使用
- write（写入）
	作用于主内存中的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中

**操作规则：**
1，read和load，store和write必须成对出现。即：read之后必须load, write之前也必须先store
2，不允许线程丢弃他最近的assign操作。即：工作变量的数据改变之后，必须告知主存
3，不允许线程将未assign的数据同步到主存
4，新变量在主内存中诞生，不允许工作内存直接use一个未被初始化的变量。
5，一个变量同一时间只能被一个线程lock。多次lock后，必须执行相同次数的unlock才能解锁。即：同一个线程对一个变量加锁后，可以继续加锁，同时在释放锁的时候释放锁次数必须和加锁次数相同。
6，不能对未被lock的变量进行unlock操作。也不能unlock一个被其他线程lock的变量
7，对变量执行lock操作，就会清空工作空间该变量的值，执行引擎使用这个变量之前，需要重新执行load或者assign操作初始化变量的值
8，对一个变量进行unlock操作之前，必须把此变量同步回主存。即：执行store和write操作

##### JMM 重排序

###### 重排序对多线程的影响
flag变量是个标记，用来标识变量a是否已被写入。这里假设有两个线程A和B，A首先执行`writer()`方法，随后B线程接着执行`reader()`方法。线程B在执行操作4时，能否看到线程A在操作1对共享变量`a`的写入？
```java
class ReorderExample {
    int a = 0;
    boolean flag = false;
 
    public void writer() {
        a = 1;                   //1
        flag = true;             //2
    }
 
    Public void reader() {
        if (flag) {              //3
            int i =  a * a;      //4
            ......
        }
    }
}
```
操作1和操作2没有数据依赖关系，编译器和处理器可以对这两个操作重排序；
操作3和操作4存在控制依赖关系，当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程B的处理器可以提前读取并计算`a*a`，然后把计算结果临时保存到一个名为重排序缓冲（reorder buffer `ROB`）的硬件缓存中。当接下来操作3的条件判断为`true`时，就把该计算结果写入变量`i`中。

可以看出，*猜测执行*实质上对操作3和4做了重排序。重排序在这里破坏了多线程程序的语义！

在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是`as-if-serial`语义允许对存在控制依赖的操作做重排序的原因）；
但**在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果**。


##### 先行发生原则 （happens-before）
happens-before是JMM定义的2个操作之间的偏序关系：如果操作A先行发生于操作B，则A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等。
如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在happens-before关系。
**注意**
    两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。

#### 扩容（高可用）



#### 队列

#### 限流/降级/熔断

##### 限流

限制流量
###### 常见限流算法
- 计数器算法 
滑动窗口；有新的请求进来时，时间窗口内请求计数+1；超过阈值时不处理新的请求
- 令牌桶算法 
匀速放入令牌。有新的请求进来时，先取走令牌再处理请求；令牌不足时不处理新的请求
- 漏水桶算法 
匀速流出水；有新的请求进来时，先流入水再处理请求；桶满时不处理新的请求

##### 降级
降低服务的优先级

##### 熔断

当某个目标服务调用慢或者有大量超时，熔断该服务的调用，对于后续调用请求，不在继续调用目标服务，直接返回，快速释放资源。待目标服务情况好转时再恢复调用。

##### 雪崩效应

一种因服务提供者的不可用导致服务调用者的不可用,并将不可用逐渐放大的过程

#### 线程安全
当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替执行，并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确的行为，那么就称这个类时线程安全的。
##### 并发容器 J.U.C (java.util.concurrent)

| 非线程安全 | 线程安全                 |
| --------- | ---------------------- |
| ArratList | CopyOnWriteArraySet    |
| HashSet   | CopyOnWriteArraySet    |
| TreeSet   | ConcurrentSkipListSet  |
| HashMap   | ConcurrentHashMap      |
| TreeMap   | ConcurrentSkipListMap  |

### 最佳实践
- 使用本地变量
- 使用不可变类
- 最小化锁的作用域范围：S=1/(1-a+a/n)
- 使用线程池的Executor，而不是直接new Thread执行
- 宁可使用同步也不要使用线程的wait和notify
- 使用BlockingQueue实现生产-消费模式
- 使用并发集合而不是加了锁的同步集合
- 使用Semaphore创建有界的访问
- 宁可使用同步代码块，也不使用同步方法
- 避免使用静态变量
- 多线程wait时使用while而不是if

### 参考

- [Java内存模型总结 --AlphaWang](https://blog.csdn.net/vking_wang/article/details/8574376)
- [Java内存模型一（基础）--程晓明](https://www.infoq.cn/article/java-memory-model-1)
- [Java内存模型二（重排序）--程晓明](https://www.infoq.cn/article/java-memory-model-2)
- [Java内存模型三（顺序一致性）--程晓明](https://www.infoq.cn/article/java-memory-model-3)
- [Java内存模型四（volatile）--程晓明](https://www.infoq.cn/article/java-memory-model-4)
- [Java内存模型五（锁）--程晓明](https://www.infoq.cn/article/java-memory-model-5)
- [Java内存模型六（final）--程晓明](https://www.infoq.cn/article/java-memory-model-6)
- [Java内存模型七（总结）--程晓明](https://www.infoq.cn/article/java-memory-model-7)

